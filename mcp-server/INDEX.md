# mcp-server/ — Model Context Protocol Server

## Purpose

Standalone MCP server that exposes 5 tools for Copilot Agent Mode to query cached code summaries. Reads from `.codebase/` folder and provides instant, structured access to project architecture without burning context tokens.

## Contents

### Source Code
- [**src/**](src/INDEX.md) — TypeScript source for MCP server
- [**package.json**](package.json) — Dependencies (MCP SDK, TypeScript)
- [**tsconfig.json**](tsconfig.json) — TypeScript configuration
- [**README.md**](README.md) — MCP server documentation

### Build Output
- **dist/** — Compiled JavaScript (generated by `npm run build`)

## Architecture

```
.vscode/mcp.json (tells VS Code to start this server)
    ↓
mcp-server/dist/index.js (runs as stdio process)
    ↓
Registers 5 tools with MCP protocol
    ↓
Copilot Agent Mode discovers tools
    ↓
When user asks, Copilot calls tools
    ↓
Server reads .codebase/ summaries (instant, no LLM)
    ↓
Returns JSON to Copilot
```

## Available Tools

| Tool | Purpose | Cost |
|------|---------|------|
| `get_file_summary` | Instant cached lookup | None (file I/O) |
| `analyze_file` | Generate/update summary | Low (cheap Copilot model) |
| `search_summaries` | Find by dependency/component/keyword | None (file I/O) |
| `list_summaries` | List all cached files | None (file I/O) |
| `get_dependency_graph` | Show relationships | None (file I/O) |

## Configuration

Registered in [../.vscode/mcp.json](../.vscode/mcp.json):
```json
{
  "servers": {
    "lunaEncyclopedia": {
      "type": "stdio",
      "command": "node",
      "args": ["mcp-server/dist/index.js"]
    }
  }
}
```

## Build Commands

```bash
npm install              # Install @modelcontextprotocol/sdk
npm run build           # tsc — compile TypeScript → dist/
npm run watch           # Auto-rebuild on file changes
npm run start           # Test run locally
```

## Notes

- **No external API calls** — Reads only from `.codebase/` folder
- **Stateless** — Each request is independent
- **Fast** — File I/O only, no LLM inference
- **Stub implementation** — `analyze_file` tool returns placeholder; would need bridge to extension for actual Copilot API calls

## Future: Copilot Integration

Currently, `analyze_file` is a stub. To enable on-demand summary generation:
1. Add HTTP/IPC bridge to extension's Copilot API
2. MCP server calls bridge when `analyze_file` requested
3. Extension generates summary via Copilot Chat API
4. MCP returns result to Copilot

This would enable seamless "generate summary for new file" without regenerating everything.

## See Also

- [src/INDEX.md](src/INDEX.md) — MCP server implementation details
- [../README.md](../README.md) — Main project documentation
- [../mcp-server/README.md](README.md) — MCP server user guide
